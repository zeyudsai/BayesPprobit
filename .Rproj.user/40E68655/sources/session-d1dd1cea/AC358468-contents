---
title: "Getting Started with BayesPprobit"
author: "Your Name"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Getting Started with BayesPprobit}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5
)
library(BayesPprobit)
```

## Introduction

The BayesPprobit package implements Bayesian p-generalized probit regression with efficient data compression using coresets. The package extends standard probit regression by introducing a flexible shape parameter p that controls the tail behavior of the link function.

### Key Features

- Flexible p-generalized probit models
- MCMC sampling with multiple chains
- Efficient data compression using coresets
- Comprehensive diagnostic tools

## Quick Start

### Installation

```{r eval=FALSE}
install.packages("BayesPprobit")
```

### Basic Usage

Let's start with a simple example using simulated data:

```{r}
# Generate example data
set.seed(123)
n <- 1000  # number of observations
d <- 5     # number of features

# Design matrix
X <- matrix(rnorm(n*d), n, d)
# True parameters
beta_true <- rnorm(d)
p_true <- 2

# Generate response
eta <- X %*% beta_true
pi <- pgnorm(eta, p_scale(p_true), p_true)
y <- rbinom(n, 1, pi)

# Fit model
fit <- multi_chain(
  n_sim = 2000,
  burn_in = 500,
  X = X,
  y = y,
  initial_theta = rep(0, d),
  p = 2,
  n_chains = 3
)
```

### Examining Results

```{r}
# Plot MCMC chains
plot_chains <- function(fit) {
  par(mfrow = c(2,2))
  # Plot p parameter chain
  plot(fit$p_chains[[1]], type = "l",
       xlab = "Iteration", ylab = "p",
       main = "Trace Plot of p")
  
  # Plot first beta parameter
  plot(fit$beta_chains[[1]][,1], type = "l",
       xlab = "Iteration", ylab = expression(beta[1]),
       main = "Trace Plot of β1")
  
  # Plot posterior density of p
  density_p <- density(fit$p_chains[[1]])
  plot(density_p, main = "Posterior Density of p",
       xlab = "p")
  
  # Plot true vs estimated betas
  plot(beta_true, fit$posterior_beta,
       xlab = "True β", ylab = "Estimated β",
       main = "True vs Estimated β")
  abline(0,1, col = "red", lty = 2)
}

plot_chains(fit)
```

## Model Details

### The p-Generalized Probit Model

The p-generalized probit model extends standard probit regression by using a p-generalized Gaussian distribution (p-GGD) as the link function. The probability model is:

$P(Y_i = 1|X_i) = \Phi_p(X_i^\top\beta)$

where $\Phi_p$ is the CDF of the p-GGD.

The parameter p controls the tail behavior:
- p = 1: Similar to logistic regression
- p = 2: Standard probit regression 
- p > 2: Heavier tails
- p < 2: Lighter tails

### MCMC Sampling

The sampling algorithm uses a Metropolis-Hastings within Gibbs scheme:

1. Sample latent variables Z from truncated p-GGD
2. Update regression coefficients β via Gibbs step
3. Update p via Metropolis-Hastings

## Scalable Computation with Coresets

For large datasets, we can use coresets to compress the data while preserving the likelihood structure:

```{r}
# Generate larger dataset
n_large <- 100000
X_large <- matrix(rnorm(n_large*d), n_large, d)
y_large <- rbinom(n_large, 1, 0.5)

# Construct coreset
cs <- compute_coreset(
  X = X_large,
  y = y_large,
  coreset_size = 1000,
  method = "leverage"
)

# Fit model on coreset
fit_cs <- multi_chain(
  n_sim = 2000,
  burn_in = 500,
  X = X_large[cs$indices,],
  y = y_large[cs$indices],
  initial_theta = rep(0, d),
  p = 2,
  n_chains = 3
)
```

### Coreset Methods

The package implements several coreset construction methods:

1. Leverage score sampling
- Based on p-norm leverage scores
- Preserves important data points

2. One-shot coresets
- Valid for multiple p values
- More robust but larger size

3. Uniform sampling
- Simple baseline
- No theoretical guarantees

## Advanced Topics

### Convergence Diagnostics

It's important to check MCMC convergence using multiple diagnostics:

```{r}
# Gelman-Rubin diagnostic
gelman.diag <- function(chains) {
  # Implementation of Gelman-Rubin diagnostic
}

# Example convergence check
diag <- gelman.diag(fit$beta_chains)
print(diag)
```

### Parameter Tuning

Guidelines for tuning key parameters:

1. MCMC parameters
- n_sim: Typically 2000-5000 iterations
- burn_in: 20-25% of total iterations
- n_chains: At least 3 chains

2. Coreset parameters
- coreset_size: Trade-off between speed and accuracy
- sketch_size: Usually d^2 is sufficient

## Real Data Example

Let's analyze a real dataset:

```{r eval=FALSE}
# Load credit card default data
data(credit)

# Preprocess
X <- as.matrix(credit[, -1])  # remove response
y <- credit$default

# Standardize predictors
X <- scale(X)

# Fit model
fit_credit <- multi_chain(
  n_sim = 5000,
  burn_in = 1000,
  X = X,
  y = y,
  initial_theta = rep(0, ncol(X)),
  p = 2,
  n_chains = 3
)

# Examine results
summary(fit_credit)
plot_chains(fit_credit)
```

## Performance Tips

1. Use coresets for large datasets (n > 10000)
2. Parallel chains for faster computation
3. Monitor memory usage with large design matrices
4. Consider standardizing predictors

## References

- Ding et al. (2024). Scalable Bayesian p-generalized probit and logistic regression
- Munteanu et al. (2022). p-Generalized probit regression and scalable maximum likelihood estimation

## Session Info

```{r}
sessionInfo()
```
